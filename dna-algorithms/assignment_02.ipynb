{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook contains code, notes, and solutions to week two's programming assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Read Alignment\n",
    "\n",
    "Modified implementation of the Naive read alignment algorithm that (potentially) allows for mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5 requires something slightly different (mismatch tolerance)\n",
    "# occurrences, num_alignments, num_character_comparisons = naive_with_counts(p, t)\n",
    "#  print(occurrences, num_alignments, num_character_comparisons)\n",
    "def naive_mismatch(target, reference, n_mismatch=0):\n",
    "    \"\"\"\n",
    "    Modified version of naive, exact-match algo.\n",
    "    \n",
    "    Args:\n",
    "        reference (Seq): reference genome\n",
    "        target (Seq): target sequence\n",
    "        n_mismatch(int): number of mismatches to tolerate\n",
    "\n",
    "    Returns:\n",
    "        occurences (list): list of occurences\n",
    "\n",
    "    Note:\n",
    "        A special case of this algorithm with n_match=0 is an\n",
    "        \"exact-match\" implementation of the naive read alignment\n",
    "        algorithm.\n",
    "    \"\"\"\n",
    "\n",
    "    occurrences = []\n",
    "\n",
    "    # Additional counters for assignment purposes\n",
    "    num_alignments = 0\n",
    "    num_character_comparisons = 0\n",
    "\n",
    "    for i in range(len(reference) - len(target) + 1):  # loop over alignments\n",
    "\n",
    "        match = True\n",
    "\n",
    "        # Track alignments\n",
    "        num_alignments += 1\n",
    "\n",
    "        # Track mismatch count\n",
    "        mismatch = 0\n",
    "\n",
    "        for j in range(len(target)):\n",
    "            num_character_comparisons += 1\n",
    "\n",
    "            if reference[i+j] != target[j]:\n",
    "                mismatch += 1\n",
    "\n",
    "            if mismatch > n_mismatch:\n",
    "                match = False\n",
    "                break\n",
    "\n",
    "        if match:\n",
    "            occurrences.append(i)  # all chars matched; record\n",
    "\n",
    "    return occurrences, num_alignments, num_character_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40] 41 46\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "p = 'word'\n",
    "t = 'there would have been a time for such a word'\n",
    "occurrences, num_alignments, num_character_comparisons = naive_mismatch(p, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 19] 20 35\n"
     ]
    }
   ],
   "source": [
    "# Example 2\n",
    "p = 'needle'\n",
    "t = 'needle need noodle needle'\n",
    "occurrences, num_alignments, num_character_comparisons = naive_mismatch(p, t)\n",
    "\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The naive read-alignment implementation above appears to work as intended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boyer-Moore\n",
    "\n",
    "This section contains a (slightly) modified implementation of the BM algorithm that allows for mismatch tolerances. Note that Hamming distance rather than edit distance, in this implementation. In other words, only substitutions are considered rather than insertions and deletions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to import the Boyer-Moore classes and functions\n",
    "from bm_preproc import BoyerMoore\n",
    "\n",
    "# Now, import other modules we'll likely need along the way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is lifted directly from the programming reading.\n",
    "#  Note: I made some small changes because my OCD won't allow for\n",
    "#  the super crappy linting and programming practices.\n",
    "def boyer_moore(p, p_bm, t):\n",
    "    \"\"\"\n",
    "    Do Boyer-Moore matching.\n",
    "\n",
    "    At its heart, Boyer-Moore is an exact-matching algorithm\n",
    "    that allows the user to skip many of the potential read\n",
    "    alignments using a simple heuristic:\n",
    "    \n",
    "        - Compare the pattern and the text backwards\n",
    "        - If a \"bad character\" is found, then advance\n",
    "          the pattern until the \"bad character\" matches\n",
    "          the underlying text.\n",
    "        - If a \"good suffix\" is found followed by a mismatch,\n",
    "          then advance the pattern until the same suffix is found.\n",
    "          This will ensure that there is a match in this discovered\n",
    "          region.\n",
    " \n",
    "    Note:\n",
    "        This implementation has no mismatch tolerance.\n",
    "        Must be modified for the programming assigment.\n",
    "\n",
    "    Args:\n",
    "        p (string): pattern (sequence)\n",
    "        p_bm (BoyerMoore): preprocessed BoyerMoore object\n",
    "        t (text): string to which the pattern is compared\n",
    "\n",
    "    Returns:\n",
    "        occurrences (list): a list of exact matches\n",
    "    \"\"\"\n",
    "\n",
    "    # Start at beginning of the sequence (offset of 0)\n",
    "    i = 0\n",
    "\n",
    "    # Track matches as a list\n",
    "    occurrences = []\n",
    "\n",
    "    # Counters for tracking purposes\n",
    "    num_alignments = 0\n",
    "    num_character_comparisons = 0\n",
    "\n",
    "    # Also, we want to build in mismatch tolerance\n",
    "    while i < len(t) - len(p) + 1:\n",
    "\n",
    "        # Checking an alignment\n",
    "        num_alignments += 1\n",
    "\n",
    "        # By default, we will move to the next position\n",
    "        shift = 1\n",
    "\n",
    "        mismatched = False\n",
    "\n",
    "        # We move backwards through the pattern to find\n",
    "        # a potentially matching suffix.\n",
    "        #\n",
    "        # j in this case refers to the position within the pattern\n",
    "        # sequence.\n",
    "        for j in range(len(p)-1, -1, -1):\n",
    "\n",
    "            # Checking a new character\n",
    "            num_character_comparisons += 1\n",
    "\n",
    "            if p[j] != t[i+j]:\n",
    "    \n",
    "                # Lookup the maximum shift based on the\n",
    "                # bad characte rule\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                \n",
    "                # Lookup maximum shift based on the good suffix rule\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                \n",
    "                # Figure out what the maximal shift is overall\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "\n",
    "                mismatched = True\n",
    "\n",
    "            if mismatched:\n",
    "                break\n",
    "\n",
    "        if not mismatched:\n",
    "            occurrences.append(i)\n",
    "            \n",
    "            # Advances to the next position\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "\n",
    "        i += shift\n",
    "\n",
    "    return occurrences, num_alignments, num_character_comparisons\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40] 12 15\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "p = 'word'\n",
    "t = 'there would have been a time for such a word'\n",
    "lowercase_alphabet = 'abcdefghijklmnopqrstuvwxyz '\n",
    "p_bm = BoyerMoore(p, lowercase_alphabet)\n",
    "occurrences, num_alignments, num_character_comparisons = boyer_moore(p, p_bm, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 19] 5 18\n"
     ]
    }
   ],
   "source": [
    "# Example 2\n",
    "p = 'needle'\n",
    "t = 'needle need noodle needle'\n",
    "p_bm = BoyerMoore(p, lowercase_alphabet)\n",
    "occurrences, num_alignments, num_character_comparisons = boyer_moore(p, p_bm, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "Notes for the regular quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "p = 'TAATAAA'\n",
    "p_bm = BoyerMoore(p, 'ATGC')\n",
    "shift = p_bm.bad_character_rule(4, 'T')\n",
    "n_skip = shift - 1\n",
    "print(n_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Question 2\n",
    "p = 'TAATTAA'\n",
    "p_bm = BoyerMoore(p, 'ATGC')\n",
    "shift = p_bm.good_suffix_rule(4)\n",
    "n_skip = shift - 1\n",
    "print(n_skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Quiz\n",
    "\n",
    "This section contains quiz notes and solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to load the genome\n",
    "from Bio.Seq import Seq\n",
    "import Bio.SeqIO\n",
    "\n",
    "genome = list(Bio.SeqIO.parse('chr1.GRCh38.excerpt.fasta', 'fasta')).pop().seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56922] 799954 984143\n"
     ]
    }
   ],
   "source": [
    "# Question 1/2\n",
    "p = 'GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG'\n",
    "occurrences, num_alignments, num_character_comparisons = naive_mismatch(p, genome)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56922] 127974 165191\n"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "p = 'GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG'\n",
    "p_bm = BoyerMoore(p, 'ATGC')\n",
    "occurrences, num_alignments, num_character_comparisons = boyer_moore(p, p_bm, genome)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4\n",
    "#  This requires considerably more work, so will break it into sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the kmer index\n",
    "# from kmer_index import Index, SubseqIndex\n",
    "%run kmer_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the pigeonhole principle using an Index to speed up performance\n",
    "# The code below is the original approximate matching algo\n",
    "# This does *not* leverage an index.\n",
    "def approximate_match(p, t, n, index=None):\n",
    "    \"\"\"\n",
    "    Approximate matching using the Pigeonhole principle/Boyer-Moore.\n",
    "\n",
    "    The algorithm does the following:\n",
    "        - Breaks the pattern (p) into n + 1 segments (partitioning)\n",
    "        - Finds partitions that match t exactly\n",
    "        - Verifies the match by checking if the surrounding partitions\n",
    "          also match t (to within tolerance limits)\n",
    "\n",
    "    Args:\n",
    "        p (string): pattern\n",
    "        t (string): text\n",
    "        n (int): number of mismatches to tolerate\n",
    "\n",
    "    Returns:\n",
    "        all_matches (list): a list of offsets where an approximate\n",
    "                            match occurs\n",
    "\n",
    "    Note:\n",
    "        The code has been modified slightly from lecture materials\n",
    "        and commented heavily to help cbishop in the future recall\n",
    "        core principles motivating each code segment.\n",
    "    \"\"\"\n",
    "\n",
    "    # The pattern (p) is broken into segments of this length.\n",
    "    # Note that this may be shorter for the last segment\n",
    "    # depending on whether or not len(p) is a multiple of n + 1\n",
    "    #\n",
    "    # Note: n+1 here because we are leveraging the Pigeonhole principle\n",
    "    #       That is, if we tolerate n mismatches, then we need n+1\n",
    "    #       partitions to guarantee that at least one partition will\n",
    "    #       match T exactly if an approximate match exists\n",
    "    segment_length = int(round(len(p) / (n+1)))\n",
    "\n",
    "    # Use a set here so we remove redundant entries\n",
    "    all_matches = set()\n",
    "\n",
    "    n_index_hits = 0\n",
    "\n",
    "    # Loop over partitions\n",
    "    for i in range(n+1):\n",
    "\n",
    "        start = i*segment_length\n",
    "        end = min((i+1)*segment_length, len(p))\n",
    "\n",
    "        # Preprocessing of partition\n",
    "        partition = p[start:end]\n",
    "\n",
    "        # If an index is available, use that\n",
    "        # Otherwise, default to BM\n",
    "        if index is not None:\n",
    "            matches = index.query(partition)\n",
    "            # Need to add in the start again\n",
    "            # or the logic below will always break\n",
    "#             matches = [m + start for m in matches]\n",
    "        else:\n",
    "            p_bm = BoyerMoore(partition, alphabet='ACGT')\n",
    "\n",
    "            # Finds exact matches of specified partition\n",
    "            matches, _, _ = boyer_moore(partition, p_bm, t)\n",
    "\n",
    "        # Track the total number if index hits\n",
    "        n_index_hits += len(matches)\n",
    "\n",
    "        # Extend matching partitions to see if whole p matches\n",
    "        for m in matches:\n",
    "            \n",
    "            # Verify that the match we found is in the appropriate\n",
    "            # index range\n",
    "            if m < start or m-start+len(p) > len(t):\n",
    "                continue\n",
    "\n",
    "            # Track the number of mismatches in this comparison\n",
    "            mismatches = 0\n",
    "\n",
    "            # Check before the partition\n",
    "            for j in range(0, start):\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "\n",
    "            # Check after the partition\n",
    "            for j in range(end, len(p)):\n",
    "                if not p[j] == t[m-start+j]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "\n",
    "            # Verify that the mismatches are within tolerance\n",
    "            if mismatches <= n:\n",
    "                all_matches.add(m - start)\n",
    "\n",
    "    # Convert to list so the result is easier to work with\n",
    "    return list(all_matches), n_index_hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Need to convert the genome (currently a sequence) to a string\n",
    "#  If the conversion is not done, then the index creation takes forever\n",
    "genome_str = ''.join(list(genome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index the genome\n",
    "index = Index(genome_str, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "p = 'GGCGCGGTGGCTCACGCCTGTAAT'\n",
    "\n",
    "occurrences, n_index_hits = approximate_match(p, genome, 2, index)\n",
    "print(len(occurrences))\n",
    "# occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 5\n",
    "n_index_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 6\n",
    "#  This requires a new index type to be created (SubseqIndex)\n",
    "sub_index = SubseqIndex(genome_str, 8, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_match(p, t, offset, n):\n",
    "    \"\"\"\n",
    "    Verify that p and t match within tolerance limits\n",
    "    \"\"\"\n",
    "    \n",
    "    n_mismatches = 0\n",
    "    \n",
    "    t_subset = t[offset:offset+len(p)]\n",
    "\n",
    "    for i in range(len(p)):\n",
    "        \n",
    "        if t_subset[i] != p[i]:\n",
    "            \n",
    "            n_mismatches += 1\n",
    "    \n",
    "        if n_mismatches > n:\n",
    "            \n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def query_index(p, t, index):\n",
    "    \"\"\"\n",
    "    Wrapper to query against a subsequence index.\n",
    "    \n",
    "    Args:\n",
    "        p (str): pattern\n",
    "        t (str): text\n",
    "        index (SubseqIndex): subsequence index\n",
    "\n",
    "    Returns\n",
    "        hits (list): offsets where p matches t\n",
    "        n_index_hits (int): total number of index hits\n",
    "    \"\"\"\n",
    "\n",
    "    hits = []\n",
    "\n",
    "    n_index_hits = 0\n",
    "\n",
    "    # This will tell me where to start looking\n",
    "    for i in range(index.ival):\n",
    "        partition = p[i:]\n",
    "        _hits = index.query(partition)\n",
    "        n_index_hits += len(_hits)\n",
    "\n",
    "        hits += [h - i for h in _hits]\n",
    "\n",
    "    # Now, look more broadly in this area\n",
    "    hits = list(set(hits))\n",
    "\n",
    "    # Verify this is an approximate match\n",
    "    #  hard-coded the 2 mismatches for now cuz that's all we're doing\n",
    "    hits = [h for h in hits if verify_match(p, t, h, 2)]\n",
    "\n",
    "    return hits, n_index_hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 14]\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "t = 'to-morrow and to-morrot and to-morrow creeps in this petty pace'\n",
    "p = 'to-morrow and to-morrow'\n",
    "subseq_ind = SubseqIndex(t, 8, 3)\n",
    "# occurrences = subseq_ind.query(p)\n",
    "occurrences, n_index_hits = query_index(p, t, subseq_ind)\n",
    "print(occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(n_index_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 'GGCGCGGTGGCTCACGCCTGTAAT'\n",
    "subseq_ind = SubseqIndex(genome_str, 8, 3)\n",
    "hits, n_index_hits = query_index('GGCGCGGTGGCTCACGCCTGTAAT', genome, subseq_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 79)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hits), n_index_hits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
